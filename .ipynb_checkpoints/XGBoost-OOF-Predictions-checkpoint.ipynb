{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get out-of-fold predictions from xgboost.cv in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOF Predictions in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "data(mtcars)\n",
    "xgb_params = list(\n",
    "  max_depth = 1,\n",
    "  eta = 0.01\n",
    ")\n",
    "x = model.matrix(mpg~0+., mtcars)\n",
    "train = xgb.DMatrix(x, label=mtcars$mpg)\n",
    "res = xgb.cv(xgb_params, train, 100, prediction=TRUE, nfold=5)\n",
    "print(head(res$pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOF Predictions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. using the sklearn wrapper for xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import cross_val_predict as cvp\n",
    "from sklearn import datasets\n",
    "X = datasets.load_iris().data[:, :2]\n",
    "y = datasets.load_iris().target\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "y_pred = cvp(xgb_model, X, y, cv=3, n_jobs = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A Hacky Callback Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_prediction():\n",
    "    \"\"\"\n",
    "    Dirty global variable callback hack.\n",
    "    \"\"\"\n",
    "\n",
    "    global cv_prediction_dict\n",
    "\n",
    "    def callback(env):\n",
    "        \"\"\"internal function\"\"\"        \n",
    "        cv_prediction_list = []\n",
    "\n",
    "        for i in [0, 1, 2, 3, 4]:\n",
    "            cv_prediction_list.append([env.cvfolds[i].bst.predict(env.cvfolds[i].dtest)])\n",
    "\n",
    "        cv_prediction_dict['cv'] = cv_prediction_list\n",
    "\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the callback from xgboost.cv() as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_prediction_dict = {}\n",
    "xgb.cv(xgb_params, train, 100, callbacks=[oof_prediction()]), nfold=5)\n",
    "pos_oof_predictions = cv_prediction_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Callback Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def cv_misc_callback(model_dir:str=None, oof_preds:list=None, maximize=True):\n",
    "    \"\"\"\n",
    "    To reduce memory and disk storage, only best models and best oof preds and stored\n",
    "    For classification, the preds are scores before applying sigmoid.\n",
    "    \"\"\"\n",
    "    state = {}\n",
    "    def init(env):\n",
    "        if maximize:\n",
    "            state['best_score'] = -np.inf\n",
    "        else:\n",
    "            state['best_score'] = np.inf\n",
    "        if (model_dir is not None) and  (not os.path.isdir(model_dir)):\n",
    "            os.mkdir(model_dir)\n",
    "\n",
    "        if oof_preds is not None:\n",
    "            for i, _ in enumerate(env.cvfolds):\n",
    "                oof_preds.append(None)\n",
    "\n",
    "    def callback(env):\n",
    "        if not state:\n",
    "            init(env)\n",
    "        best_score = state['best_score']\n",
    "        score = env.evaluation_result_list[-1][1]\n",
    "        if (maximize and score > best_score) or (not maximize and score < best_score):\n",
    "            for i, cvpack in enumerate(env.cvfolds):\n",
    "                if model_dir is not None:\n",
    "                    cvpack.bst.save_model(f'{model_dir}/{i}.model')\n",
    "                if oof_preds is not None:\n",
    "                    oof_preds[i] = cvpack.bst.predict(cvpack.dtest)\n",
    "            state['best_score'] = score\n",
    "\n",
    "    callback.before_iteration = False\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = []\n",
    "oof_preds = []\n",
    "history = xgb.cv(params, dtrain, num_boost_round=1000,\n",
    "                 folds=folds, early_stopping_rounds=40, seed=RANDOM_SEED,\n",
    "                 callbacks=[cv_misc_callback('./models', oof_preds), xgb.callback.print_evaluation(period=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping preds list to oof_preds of train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_proba = np.zeros(av_data.shape[0])\n",
    "for i, (trn_idx, val_idx) in enumerate(folds):\n",
    "    oof_preds_proba[val_idx] = sigmoid(oof_preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Read Data\n",
    "print(\"Reading Dataset...\")\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "target = np.array(train[\"target\"])\n",
    "target_log = np.log1p(target) # Log transform target as the evaluation metric uses it\n",
    "xtrain = np.array(train.iloc[:,2:])\n",
    "print(\"Shape of training data: {}\".format(np.shape(xtrain)))\n",
    "\n",
    "# Define Model \n",
    "xgb_model = XGBRegressor(max_depth=6, learning_rate=0.1, n_estimators=70,\n",
    "                         min_child_weight=100, subsample=1.0, \n",
    "                         colsample_bytree=0.8, colsample_bylevel=0.8,\n",
    "                         random_state=42, n_jobs=4)\n",
    "\n",
    "# Make OOF predictions using 5 folds\n",
    "print(\"Cross Validating...\")\n",
    "oof_preds_log = cross_val_predict(xgb_model, xtrain, target_log, cv=5, \n",
    "                                  n_jobs=1, method=\"predict\")\n",
    "                                  \n",
    "# Calculate RMSLE (RMSE of Log(1+y))\n",
    "cv_rmsle = np.sqrt(mean_squared_error(target_log, oof_preds_log))\n",
    "print(\"\\nOOF RMSLE Score: {:.4f}\".format(cv_rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of training data: {}\".format(np.shape(xtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_vs_actual_sale_price_xgb(self, xgb_params, x_train, y_train, seed, title_name):\n",
    "        # Split the training data into an extra set of test\n",
    "        x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train)\n",
    "        dtrain_split = xgb.DMatrix(x_train_split, label=y_train_split)\n",
    "        dtest_split = xgb.DMatrix(x_test_split)\n",
    "\n",
    "        res = xgb.cv(xgb_params, dtrain_split, num_boost_round=1000, nfold=4, seed=seed, stratified=False,\n",
    "                     early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n",
    "\n",
    "        best_nrounds = res.shape[0] - 1\n",
    "        print(np.shape(x_train_split), np.shape(x_test_split), np.shape(y_train_split), np.shape(y_test_split))\n",
    "        gbdt = xgb.train(xgb_params, dtrain_split, best_nrounds)\n",
    "        y_predicted = gbdt.predict(dtest_split)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(y_test_split, y_predicted, s=20)\n",
    "        rmse_pred_vs_actual = self.rmse(y_predicted, y_test_split)\n",
    "        plt.title(''.join([title_name, ', Predicted vs. Actual.', ' rmse = ', str(rmse_pred_vs_actual)]))\n",
    "        plt.xlabel('Actual Sale Price')\n",
    "        plt.ylabel('Predicted Sale Price')\n",
    "        plt.plot([min(y_test_split), max(y_test_split)], [min(y_test_split), max(y_test_split)])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
