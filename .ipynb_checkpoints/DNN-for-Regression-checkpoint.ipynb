{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras: Regression-based neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "path=\"C:/yourdirectory\"\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are implementing a neural network, the variables need to be normalized in order for the neural network to interpret them properly. Therefore, our variables are transformed using the MaxMinScaler():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "dataset=np.loadtxt(\"cars.csv\", delimiter=\",\")\n",
    "x=dataset[:,0:5]\n",
    "y=dataset[:,5]\n",
    "y=np.reshape(y, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale=scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then split into training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model Configuration: Neural Network API\n",
    "Now, we train the neural network. We are using the five input variables (age, gender, miles, debt, and income), along with two hidden layers of 12 and 8 neurons respectively, and finally using the linear activation function to process the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean_squared_error (mse) and mean_absolute_error (mae) are our loss functions – i.e. an estimate of how accurate the neural network is in predicting the test data. We can see that with the validation_split set to 0.2, 80% of the training data is used to test the model, while the remaining 20% is used for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we can see that the more epochs are run, the lower our MSE and MAE become, indicating improvement in accuracy across each iteration of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Output\n",
    "\n",
    "Let’s now fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that keras is calculating both the training loss and validation loss, i.e. the deviation between the predicted y and actual y as measured by the mean squared error.\n",
    "\n",
    "Let’s see what this looks like when we plot our respective losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])\n",
    "Xnew= scaler_x.transform(Xnew)\n",
    "ynew= model.predict(Xnew)\n",
    "#invert normalize\n",
    "ynew = scaler_y.inverse_transform(ynew) \n",
    "Xnew = scaler_x.inverse_transform(Xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Password Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = []\n",
    "big = [] \n",
    "numbers = [] \n",
    "special = []\n",
    "\n",
    "smallletters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "bigletters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' \n",
    "digits = '0123456789' \n",
    "special_char = '~`!@#$%&*()-=_+{}[]|:;\"\\',.<>/'\n",
    "\n",
    "for i in smallletters:\n",
    "    small.append(i)\n",
    "for i in bigletters: \n",
    "    big.append(i) \n",
    "for i in digits: \n",
    "    numbers.append(i) \n",
    "for i in special_char: \n",
    "    special.append(i)\n",
    "\n",
    "the_big_list = small+big+numbers+special\n",
    "\n",
    "\n",
    "length = int(input(\"How many characters long password do you want? \"))\n",
    "\n",
    "if not length or length < 0:\n",
    "    exit()\n",
    "\n",
    "import random\n",
    "password = ''\n",
    "\n",
    "if length < 4:\n",
    "    while True:\n",
    "\tpassword+=small[random.randint(0,len(small)-1)]\n",
    "\tlength-=1\n",
    "\tif not length:\n",
    "\t\tbreak\n",
    "\tpassword+=big[random.randint(0,len(big)-1)]\n",
    "\tlength-=1\n",
    "\tif not length:\n",
    "\t\tbreak\n",
    "\tpassword+=numbers[random.randint(0,len(numbers)-1)]\n",
    "\tlength-=1\n",
    "\tif not length:\n",
    "\t\tbreak\n",
    "\tpassword+=special[random.randint(0,len(special)-1)]\n",
    "\tlength-=1\n",
    "\tif not length:\n",
    "\t\tbreak\t\n",
    "\n",
    "\tprint(password)\n",
    "\n",
    "elif length >=4:\n",
    "    from_each_list = length//4\n",
    "    remaining = length%4\n",
    "\n",
    "\tfor i in range(0,from_each_list):\n",
    "\t    password+=small[random.randint(0,len(small)-1)]\n",
    "\t    password+=big[random.randint(0,len(big)-1)]\n",
    "\t    password+=numbers[random.randint(0,len(numbers)-1)]\n",
    "\t    password+=special[random.randint(0,len(special)-1)]\n",
    "\n",
    "\tif remaining and from_each_list:\n",
    "\t    for i in range(0,remaining+1):\n",
    "\t\tpassword+=the_big_list[random.randint(0,len(the_big_list)-1)]\n",
    "\n",
    "\tprint(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
